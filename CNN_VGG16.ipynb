{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nelvin/anaconda3/envs/pp3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from Preprocessing import *\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_dataset():\n",
    "    X_train = np.empty((1404,64,64,3), dtype=\"int32\")\n",
    "    Y_train = np.empty((1404,4), dtype=\"int32\")\n",
    "    \n",
    "    X_train_id_cards,Y_train_id_cards = load_train_id_cards()\n",
    "    X_train_slides,Y_train_slides = load_train_slides()\n",
    "    X_train_paper_docs,Y_train_paper_docs = load_train_paper_documents()\n",
    "    X_train_receipts,Y_train_receipts = load_train_receipts()\n",
    "    \n",
    "    for i in range(482):\n",
    "        X_train[i] = X_train_id_cards[i]\n",
    "    for i in range(316):\n",
    "        X_train[482+i] = X_train_slides[i]\n",
    "    for i in range(306):\n",
    "        X_train[798+i] = X_train_paper_docs[i]\n",
    "    for i in range(300):\n",
    "        X_train[1104+i] = X_train_receipts[i]\n",
    "    \n",
    "    for i in range(482):\n",
    "        Y_train[i] = Y_train_id_cards[i]\n",
    "    for i in range(316):\n",
    "        Y_train[482+i] = Y_train_slides[i]\n",
    "    for i in range(306):\n",
    "        Y_train[798+i] = Y_train_paper_docs[i]\n",
    "    for i in range(300):\n",
    "        Y_train[1104+i] = Y_train_receipts[i]\n",
    "        \n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset():\n",
    "    X_test = np.empty((65,64,64,3), dtype=\"int32\")\n",
    "    Y_test = np.empty((65,4), dtype=\"int32\")\n",
    "    \n",
    "    X_test_id_cards,Y_test_id_cards = load_test_id_cards()\n",
    "    X_test_slides,Y_test_slides = load_test_slides()\n",
    "    X_test_paper_docs,Y_test_paper_docs = load_test_paper_documents()\n",
    "    X_test_receipts,Y_test_receipts = load_test_receipts()\n",
    "    \n",
    "    for i in range(24):\n",
    "        X_test[i] = X_test_id_cards[i]\n",
    "    for i in range(10):\n",
    "        X_test[24+i] = X_test_slides[i]\n",
    "    for i in range(14):\n",
    "        X_test[34+i] = X_test_paper_docs[i]\n",
    "    for i in range(17):\n",
    "        X_test[48+i] = X_test_receipts[i]\n",
    "    \n",
    "    for i in range(24):\n",
    "        Y_test[i] = Y_test_id_cards[i]\n",
    "    for i in range(10):\n",
    "        Y_test[24+i] = Y_test_slides[i]\n",
    "    for i in range(14):\n",
    "        Y_test[34+i] = Y_test_paper_docs[i]\n",
    "    for i in range(17):\n",
    "        Y_test[48+i] = Y_test_receipts[i]\n",
    "        \n",
    "    return X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1404\n",
      "number of test examples = 65\n",
      "X_train shape: (1404, 64, 64, 3)\n",
      "Y_train shape: (1404, 4)\n",
      "X_test shape: (65, 64, 64, 3)\n",
      "Y_test shape: (65, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig,Y_train_orig = load_train_dataset()\n",
    "X_test_orig,Y_test_orig = load_test_dataset()\n",
    "# Normalizing for faster convergence\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "Y_train = Y_train_orig\n",
    "Y_test = Y_test_orig\n",
    "#print(Y_train[1105])\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainingModel(input_shape):\n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(8, (4, 4), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((8, 8), name='max_pool0')(X)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(16, (2, 2), strides = (1, 1), name = 'conv1')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((4, 4), name='max_pool1')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(4, activation='softmax', name='fc')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='trainingModel')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingModel = TrainingModel((X_train.shape[1],X_train.shape[2],X_train.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingModel.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 1.5561 - acc: 0.4352\n",
      "Epoch 2/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.8741 - acc: 0.6802\n",
      "Epoch 3/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.7306 - acc: 0.7543\n",
      "Epoch 4/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.6573 - acc: 0.7692\n",
      "Epoch 5/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.6054 - acc: 0.7849\n",
      "Epoch 6/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.5638 - acc: 0.8027\n",
      "Epoch 7/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.5225 - acc: 0.8148\n",
      "Epoch 8/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.4900 - acc: 0.8326\n",
      "Epoch 9/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.4561 - acc: 0.8390\n",
      "Epoch 10/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.4295 - acc: 0.8447\n",
      "Epoch 11/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.4142 - acc: 0.8490\n",
      "Epoch 12/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.3938 - acc: 0.8597\n",
      "Epoch 13/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.3787 - acc: 0.8625\n",
      "Epoch 14/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.3721 - acc: 0.8640\n",
      "Epoch 15/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.3537 - acc: 0.8775\n",
      "Epoch 16/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.3434 - acc: 0.8825\n",
      "Epoch 17/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.3346 - acc: 0.8782\n",
      "Epoch 18/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.3222 - acc: 0.8860\n",
      "Epoch 19/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.3147 - acc: 0.8910\n",
      "Epoch 20/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.3058 - acc: 0.8917\n",
      "Epoch 21/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2967 - acc: 0.8932\n",
      "Epoch 22/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.3021 - acc: 0.8946\n",
      "Epoch 23/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2916 - acc: 0.8996\n",
      "Epoch 24/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2841 - acc: 0.9024\n",
      "Epoch 25/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2764 - acc: 0.9024\n",
      "Epoch 26/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2725 - acc: 0.9124\n",
      "Epoch 27/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2722 - acc: 0.9081\n",
      "Epoch 28/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2599 - acc: 0.9138\n",
      "Epoch 29/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2633 - acc: 0.9110\n",
      "Epoch 30/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2516 - acc: 0.9209\n",
      "Epoch 31/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2483 - acc: 0.9195\n",
      "Epoch 32/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2456 - acc: 0.9188\n",
      "Epoch 33/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2388 - acc: 0.9209\n",
      "Epoch 34/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2395 - acc: 0.9160\n",
      "Epoch 35/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2358 - acc: 0.9167\n",
      "Epoch 36/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2328 - acc: 0.9209\n",
      "Epoch 37/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2241 - acc: 0.9217\n",
      "Epoch 38/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2141 - acc: 0.9323\n",
      "Epoch 39/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2188 - acc: 0.9252\n",
      "Epoch 40/40\n",
      "1404/1404 [==============================] - 2s 1ms/step - loss: 0.2058 - acc: 0.9380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd1c17cedd8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingModel.fit(x = X_train, y = Y_train, epochs = 40, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 767us/step\n",
      "\n",
      "Loss = 0.3531882168008731\n",
      "Test Accuracy = 0.8769230769230769\n"
     ]
    }
   ],
   "source": [
    "preds = trainingModel.evaluate(x = X_test, y = Y_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 70, 70, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 67, 67, 8)         392       \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 67, 67, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 67, 67, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 7, 7, 16)          528       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 7, 7, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 1,084\n",
      "Trainable params: 1,036\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainingModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on own image\n",
    "- Just for this example, I reused test examples to see what the mistakes were. \n",
    "- Should actually use a fresh set of test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(path, end):\n",
    "    for i in range(1,end):\n",
    "        # Preprocess the image first\n",
    "        img_path = path+str(i)+\".jpg\"\n",
    "        img = Image.open(img_path)\n",
    "        #imshow(img)\n",
    "        img = standardize(img)\n",
    "        img = img.reshape((1,64,64,3))/255.\n",
    "        \n",
    "        # Making predictions \n",
    "        prediction = trainingModel.predict(img)\n",
    "        #print(\"prediction results: \",prediction)\n",
    "        #print(prediction.shape)\n",
    "        index = np.unravel_index(np.argmax(prediction, axis=None), prediction.shape)\n",
    "        #print(index)\n",
    "\n",
    "        # converting results to text\n",
    "        item = index[1]\n",
    "        if item == 0:\n",
    "            print(\"It is an id card/passport.\")\n",
    "        elif item == 1:\n",
    "            print(\"It is a slide.\")\n",
    "        elif item == 2:\n",
    "            print(\"It is a paper document.\")\n",
    "        elif item == 3:\n",
    "            print(\"It is a receipt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is an id card/passport.\n",
      "It is a slide.\n",
      "It is a paper document.\n"
     ]
    }
   ],
   "source": [
    "make_prediction(\"slides_test/\",11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from testing\n",
    "- **ID cards:** 22/24, the 2 were incorrectly indentified as receipts due to it being a 2 page pic of passport which is longer.\n",
    "- **slides:** 9/10, 1 was incorrectly indentified as an id card/passport.\n",
    "- **paper_docs:** 6/14, 8 were incorrectly indentified as receipts. Technically recipts are a form of paper doc.\n",
    "- **receipts:** 14/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying transfer learning \n",
    "- Using pre-trained weights from VGG model\n",
    "- freeze all the layers and only train the last 3 layers\n",
    "- Should give a better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the type\n",
    "type(vgg16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the other layers\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your own input format (here 64x64x3)\n",
    "X_input = Input(shape=(64,64,3),name = 'image_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vgg16_conv = vgg16_model(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the fully-connected layers \n",
    "X = Flatten(name='flatten')(output_vgg16_conv)\n",
    "X = Dense(2048, activation='relu', name='fc1')(X)\n",
    "X = Dense(2048, activation='relu', name='fc2')(X)\n",
    "X = Dense(4, activation='softmax', name='predictions')(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Model(inputs=X_input, outputs=X,name='myModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 23,115,588\n",
      "Trainable params: 8,400,900\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1404 samples, validate on 65 samples\n",
      "Epoch 1/5\n",
      "1404/1404 [==============================] - 41s 29ms/step - loss: 0.7156 - acc: 0.7842 - val_loss: 0.3113 - val_acc: 0.8615\n",
      "Epoch 2/5\n",
      "1404/1404 [==============================] - 42s 30ms/step - loss: 0.2203 - acc: 0.9117 - val_loss: 0.1466 - val_acc: 0.9385\n",
      "Epoch 3/5\n",
      "1404/1404 [==============================] - 41s 30ms/step - loss: 0.1634 - acc: 0.9373 - val_loss: 0.1696 - val_acc: 0.9231\n",
      "Epoch 4/5\n",
      "1404/1404 [==============================] - 41s 29ms/step - loss: 0.0800 - acc: 0.9736 - val_loss: 0.1604 - val_acc: 0.9692\n",
      "Epoch 5/5\n",
      "1404/1404 [==============================] - 41s 29ms/step - loss: 0.0557 - acc: 0.9808 - val_loss: 0.3165 - val_acc: 0.9385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd1a82c2320>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(x = X_train, y = Y_train, epochs = 5, batch_size = 32, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 2s 27ms/step\n",
      "Loss = 0.31653624085279614\n",
      "Test Accuracy = 0.9384615384615385\n"
     ]
    }
   ],
   "source": [
    "preds = my_model.evaluate(x = X_test, y = Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_VGG(path, end):\n",
    "    for i in range(1,end):\n",
    "        # Preprocess the image first\n",
    "        img_path = path+str(i)+\".jpg\"\n",
    "        img = Image.open(img_path)\n",
    "        #imshow(img)\n",
    "        img = standardize(img)\n",
    "        img = img.reshape((1,64,64,3))/255.\n",
    "        \n",
    "        # Making predictions \n",
    "        prediction = my_model.predict(img)\n",
    "        #print(\"prediction results: \",prediction)\n",
    "        #print(prediction.shape)\n",
    "        index = np.unravel_index(np.argmax(prediction, axis=None), prediction.shape)\n",
    "        #print(index)\n",
    "\n",
    "        # converting results to text\n",
    "        item = index[1]\n",
    "        if item == 0:\n",
    "            print(\"It is an id card/passport.\")\n",
    "        elif item == 1:\n",
    "            print(\"It is a slide.\")\n",
    "        elif item == 2:\n",
    "            print(\"It is a paper document.\")\n",
    "        elif item == 3:\n",
    "            print(\"It is a receipt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double checking on test images\n",
    "- checking if the accuracy is correct\n",
    "- finding out where the mistakes are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n",
      "It is a slide.\n"
     ]
    }
   ],
   "source": [
    "make_prediction_VGG(\"slides_test/\",11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n",
      "It is an id card/passport.\n"
     ]
    }
   ],
   "source": [
    "make_prediction_VGG(\"id_cards_test/\",25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a receipt.\n",
      "It is a paper document.\n",
      "It is a paper document.\n",
      "It is a receipt.\n",
      "It is a paper document.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a paper document.\n",
      "It is a paper document.\n",
      "It is a paper document.\n",
      "It is a paper document.\n",
      "It is a paper document.\n",
      "It is a paper document.\n",
      "It is a paper document.\n"
     ]
    }
   ],
   "source": [
    "make_prediction_VGG(\"paper_documents_test/\",15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n",
      "It is a receipt.\n"
     ]
    }
   ],
   "source": [
    "make_prediction_VGG(\"receipts_test/\",18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
