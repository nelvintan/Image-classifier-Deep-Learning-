{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import everything that is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nelvin/anaconda3/envs/pp3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from Preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train data set\n",
    "details of pre-processing under Preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_dataset():\n",
    "    X_train = np.empty((1404,64,64,3), dtype=\"int32\")\n",
    "    Y_train = np.empty((1404,4), dtype=\"int32\")\n",
    "    \n",
    "    X_train_id_cards,Y_train_id_cards = load_train_id_cards()\n",
    "    X_train_slides,Y_train_slides = load_train_slides()\n",
    "    X_train_paper_docs,Y_train_paper_docs = load_train_paper_documents()\n",
    "    X_train_receipts,Y_train_receipts = load_train_receipts()\n",
    "    \n",
    "    for i in range(482):\n",
    "        X_train[i] = X_train_id_cards[i]\n",
    "    for i in range(316):\n",
    "        X_train[482+i] = X_train_slides[i]\n",
    "    for i in range(306):\n",
    "        X_train[798+i] = X_train_paper_docs[i]\n",
    "    for i in range(300):\n",
    "        X_train[1104+i] = X_train_receipts[i]\n",
    "    \n",
    "    for i in range(482):\n",
    "        Y_train[i] = Y_train_id_cards[i]\n",
    "    for i in range(316):\n",
    "        Y_train[482+i] = Y_train_slides[i]\n",
    "    for i in range(306):\n",
    "        Y_train[798+i] = Y_train_paper_docs[i]\n",
    "    for i in range(300):\n",
    "        Y_train[1104+i] = Y_train_receipts[i]\n",
    "        \n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data set\n",
    "details of pre-processing under Preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset():\n",
    "    X_test = np.empty((65,64,64,3), dtype=\"int32\")\n",
    "    Y_test = np.empty((65,4), dtype=\"int32\")\n",
    "    \n",
    "    X_test_id_cards,Y_test_id_cards = load_test_id_cards()\n",
    "    X_test_slides,Y_test_slides = load_test_slides()\n",
    "    X_test_paper_docs,Y_test_paper_docs = load_test_paper_documents()\n",
    "    X_test_receipts,Y_test_receipts = load_test_receipts()\n",
    "    \n",
    "    for i in range(24):\n",
    "        X_test[i] = X_test_id_cards[i]\n",
    "    for i in range(10):\n",
    "        X_test[24+i] = X_test_slides[i]\n",
    "    for i in range(14):\n",
    "        X_test[34+i] = X_test_paper_docs[i]\n",
    "    for i in range(16):\n",
    "        X_test[48+i] = X_test_receipts[i]\n",
    "    \n",
    "    for i in range(24):\n",
    "        Y_test[i] = Y_test_id_cards[i]\n",
    "    for i in range(10):\n",
    "        Y_test[24+i] = Y_test_slides[i]\n",
    "    for i in range(14):\n",
    "        Y_test[34+i] = Y_test_paper_docs[i]\n",
    "    for i in range(16):\n",
    "        Y_test[48+i] = Y_test_receipts[i]\n",
    "        \n",
    "    return X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extra Tests'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Extra Tests'''\n",
    "#X_train_orig,Y_train_orig = load_train_dataset()\n",
    "#im = Image.fromarray(np.uint8(X_train_orig[99])) # To convert numpy array back into an image\n",
    "#plt.imshow(im)\n",
    "#print(X_train_orig[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1404\n",
      "number of test examples = 65\n",
      "X_train shape: (1404, 64, 64, 3)\n",
      "Y_train shape: (1404, 4)\n",
      "X_test shape: (65, 64, 64, 3)\n",
      "Y_test shape: (65, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig,Y_train_orig = load_train_dataset()\n",
    "X_test_orig,Y_test_orig = load_test_dataset()\n",
    "# Normalizing for faster convergence\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "Y_train = Y_train_orig\n",
    "Y_test = Y_test_orig\n",
    "# print(X_train[0])\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ2 lines)\n",
    "    X = tf.placeholder(tf.float32, shape=(None,n_H0,n_W0,n_C0))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None,n_y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "X, Y = create_placeholders(64, 64, 3, 5)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters\n",
    "1. Weights are initialized using xavier initializer\n",
    "2. Tensorflow takes care of the bias\n",
    "3. Weights are for the 2 conv2d functions\n",
    "4. Tensorflow initializes layers for fully connected part automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [4, 4, 3, 8]\n",
    "                        W2 : [2, 2, 8, 16]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 2 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [4, 4, 3, 8], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable(\"W2\", [2, 2, 8, 16], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [ 0.00131723  0.1417614  -0.04434952  0.09197326  0.14984085 -0.03514394\n",
      " -0.06847463  0.05245192]\n",
      "W2 = [-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058\n",
      " -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228\n",
      " -0.22779644 -0.1601823  -0.16117483 -0.10286498]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess_test:\n",
    "    parameters = initialize_parameters()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess_test.run(init)\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"].eval()[1,1,1]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"].eval()[1,1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation\n",
    "Model: CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,8,8,1], strides = [1,8,8,1], padding = 'SAME')\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME')\n",
    "    # FLATTEN\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    drop_out = tf.nn.dropout(P2, 0.7) \n",
    "    # FULLY-CONNECTED without non-linear activation function (no softmax).\n",
    "    # 5 neurons in output layer. \n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, 4, activation_fn=None)\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = [[-0.4872806   0.7591747  -1.4899058  -2.2552762 ]\n",
      " [-0.29407978  0.66546303 -1.4420621  -2.0235498 ]]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = create_placeholders(64, 64, 3, 4)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(Z3, {X: np.random.randn(2,64,64,3), Y: np.random.randn(2,4)})\n",
    "    print(\"Z3 = \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute cost\n",
    "1. **tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y):** computes the softmax entropy loss. This function both computes the softmax activation function as well as the resulting loss. \n",
    "2. **tf.reduce_mean:** computes the mean of elements across dimensions of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (5, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.89869094\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = create_placeholders(64, 64, 3, 4)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(cost, {X: np.random.randn(4,64,64,3), Y: np.random.randn(4,4)})\n",
    "    print(\"cost = \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "**Steps**:\n",
    "1. create placeholders\n",
    "2. initialize parameters\n",
    "3. forward propagate\n",
    "4. compute the cost\n",
    "5. create an optimizer\n",
    "6. create a session and run a for loop for num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
    "          num_epochs = 100, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_train -- test set, of shape (None, n_y = 6)\n",
    "    X_test -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_test -- test set, of shape (None, n_y = 6)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            # Run the session to execute the optimizer and the cost, the feedict contains X_train & Y_train.\n",
    "            _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, temp_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(temp_cost)\n",
    "        \n",
    "        #saver = tf.train.Saver()\n",
    "        #save_path = saver.save(sess, \"./Desktop/model.ckpt\")\n",
    "        #print(\"Model saved in path: %s\" % save_path)\n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, parameters # does not return test accuracy yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.399171\n",
      "Cost after epoch 5: 1.244358\n",
      "Cost after epoch 10: 1.105728\n",
      "Cost after epoch 15: 0.916970\n",
      "Cost after epoch 20: 0.766241\n",
      "Cost after epoch 25: 0.680607\n",
      "Cost after epoch 30: 0.612884\n",
      "Cost after epoch 35: 0.548089\n",
      "Cost after epoch 40: 0.497268\n",
      "Cost after epoch 45: 0.471494\n",
      "Cost after epoch 50: 0.433718\n",
      "Cost after epoch 55: 0.415652\n",
      "Cost after epoch 60: 0.400238\n",
      "Cost after epoch 65: 0.386599\n",
      "Cost after epoch 70: 0.374242\n",
      "Cost after epoch 75: 0.361565\n",
      "Cost after epoch 80: 0.348695\n",
      "Cost after epoch 85: 0.337189\n",
      "Cost after epoch 90: 0.325841\n",
      "Cost after epoch 95: 0.315227\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8974359\n",
      "Test Accuracy: 0.8769231\n"
     ]
    }
   ],
   "source": [
    "_, parameters = model(X_train, Y_train, X_test, Y_test, learning_rate = 0.006, num_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
